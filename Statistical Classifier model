import pandas as pd
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
from sklearn.naive_bayes import MultinomialNB
import matplotlib.pyplot as plt

class SpamClassifier:
    def __init__(self, file_path):
        self.file_path = file_path
        self.vectorizer = None
        self.model = None

    def load_dataset(self):
        """dataset loading."""
        try:
            data = pd.read_csv(self.file_path, sep='\t', header=None, names=['label', 'text'])
            # Map labels to numerical values (spam: 1, ham: 0)
            data['label'] = data['label'].map({'ham': 0, 'spam': 1})
            return data
        except Exception as e:
            print(f"Error reading the file: {e}")
            exit()

    def preprocess_data(self, text, labels):
        """Split the data into training and testing sets and vectorize the text."""
        X_train, X_test, y_train, y_test = train_test_split(
            text, labels, test_size=0.5, random_state=34
        )

        self.vectorizer = CountVectorizer()
        X_train_bow = self.vectorizer.fit_transform(X_train)
        X_test_bow = self.vectorizer.transform(X_test)

        return X_train_bow, X_test_bow, y_train, y_test

    def train_model(self, X_train, y_train):
        """Train our model."""
        self.model = MultinomialNB()
        self.model.fit(X_train, y_train)

    def evaluate_model(self, X_test, y_test):
        """Evaluate the trained model,print metrices"""
        y_pred = self.model.predict(X_test)

        # Metrics
        accuracy = accuracy_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred, average='weighted')
        precision = precision_score(y_test, y_pred)
        print("Model Evaluation:")
        print(f"Accuracy: {accuracy:.4f}")
        print(f"Precision: {precision:.4f}")
        print(f"Recall: {recall:.4f}")
        # Classification Report ha yaaa
        print("Classification Report:")
        print(classification_report(y_test, y_pred, target_names=['ham', 'spam']))
        # Confusion Matrix Visualization haa
        plt.figure(1)  
        cm = confusion_matrix(y_test, y_pred)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal messges', 'spam'], yticklabels=['Normal messages', 'spam'])
        plt.title("Confusion Matrix")
        plt.xlabel("Predicted")
        plt.ylabel("Actual")
        plt.show()

# Main execution
if __name__ == "__main__":
    file_path = "dataset" 
    # Initialize classifier
    classifier = SpamClassifier(file_path)
    # dataset load hoo rha ha.
    data = classifier.load_dataset()
    # Preprocessing of  data
    X_train_bow, X_test_bow, y_train, y_test = classifier.preprocess_data(data['text'], data['label'])
    # model train ho rha ha
    classifier.train_model(X_train_bow, y_train)
    # model ki performance check ki ja rhi ha
    classifier.evaluate_model(X_test_bow, y_test)

